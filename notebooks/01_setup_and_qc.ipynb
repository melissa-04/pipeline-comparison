from google.colab import drive
drive.mount("/content/drive")
print("google drive connected")

drive_base = "/content/drive/MyDrive/NDS_Project
drive_dirs= [
f"{drive_base}/results/qc",           
    f"{drive_base}/results/vcf",          
    f"{drive_base}/results/comparison",    
    f"{drive_base}/results/figures",      
    f"{drive_base}/logs",                 
]

for d in drive_dirs:
 os.makedirs(d,exist_ok=True)
 print(f"{d})


local_base = "/content/ngs_project"
local_dirs = [
    f"{local_base}/raw_data",             
    f"{local_base}/reference",           
    f"{local_base}/bam",                  
    f"{local_base}/vcf",                  
    f"{local_base}/ground_truth",         
]

for d in local_dirs:
    os.makedirs(d, exist_ok=True)
    print(f" {d}")

print("All folders were created.")




import os
print(" Miniforge (Conda) kuruluyor...")
print("   Bu iÅŸlem ~2-3 dakika sÃ¼recek...\n")

# Miniforge'u indir
# -q: sessiz indirme (progress bar gÃ¶sterme)
!wget -q https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh

# Kur
# -b: batch mode (interaktif soru sorma)
# -p: kurulum dizini
!bash Miniforge3-Linux-x86_64.sh -b -p /content/miniforge3 > /dev/null 2>&1

# Ä°ndirilen kurulum dosyasÄ±nÄ± sil (artÄ±k gerek yok)
!rm Miniforge3-Linux-x86_64.sh

# Conda'yÄ± PATH'e ekle
# PATH, iÅŸletim sisteminin "komut ararken baktÄ±ÄŸÄ± dizinler listesi"
# Conda'nÄ±n bin klasÃ¶rÃ¼nÃ¼ en baÅŸa ekliyoruz ki
# "conda" yazdÄ±ÄŸÄ±nda sistem onu bulabilsin
os.environ['PATH'] = '/content/miniforge3/bin:' + os.environ['PATH']

# DoÄŸrulama
!conda --version
print(" Miniforge kuruldu!")








print(" Biyoinformatik araÃ§larÄ± kuruluyor...")
print("   Bu iÅŸle m 10-15 dakika sÃ¼rebilir. Kahve molasÄ± zamanÄ±! â˜•")
print("   Kurulacak araÃ§lar: fastqc, fastp, bwa-mem2, bowtie2,")
print("   samtools, gatk4, varscan, bcftools, multiqc\n")

!conda install -y -c bioconda -c conda-forge \
    fastqc \
    fastp \
    bwa-mem2 \
    bowtie2 \
    samtools \
    gatk4 \
    varscan \
    bcftools \
    multiqc \
    2>&1 | tail -20

print(" AraÃ§ kurulumu tamamlandÄ±!")

import subprocess
tools = {
    "fastqc":    "fastqc --version",
    "fastp":     "fastp --version 2>&1 | head -1",
    "bwa-mem2":  "bwa-mem2 version 2>&1 | head -1",
    "bowtie2":   "bowtie2 --version 2>&1 | head -1",
    "samtools":  "samtools --version | head -1",
    "gatk":      "gatk --version 2>&1 | grep 'The Genome'",
    "varscan":   "varscan 2>&1 | grep 'VarScan' | head -1",
    "bcftools":  "bcftools --version | head -1",
    "multiqc":   "multiqc --version 2>&1 | head -1",
}

print("ðŸ” AraÃ§ kurulum kontrolÃ¼:\n")
all_ok = True
for name, cmd in tools.items():
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    output = (result.stdout + result.stderr).strip().split('\n')[0]
    if output and len(output) > 0:
        print(f"   âœ… {name:12s} â†’ {output}")
    else:
        print(f"   âŒ {name:12s} â†’ KURULUM HATASI!")
        all_ok = False

if all_ok:
    print(" TÃ¼m araÃ§lar baÅŸarÄ±yla kuruldu!")
else:
    print("BazÄ± araÃ§larda sorun var. YukarÄ±daki hatalarÄ± kontrol et.")



import datetime
import os

drive_base = "/content/drive/MyDrive/NGS_Project"
log_path = f"{drive_base}/logs/environment_setup.txt"

# Sistem bilgilerini topla
cpu_count = os.cpu_count()
import psutil
ram_gb = psutil.virtual_memory().total / (1024**3)

# GPU bilgisi
try:
    gpu_result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total',
                                '--format=csv,noheader'],
                               capture_output=True, text=True)
    gpu_name = gpu_result.stdout.strip() if gpu_result.returncode == 0 else "N/A (CPU runtime)"
except FileNotFoundError:
    gpu_name = "N/A (CPU runtime)"

# AraÃ§ versiyonlarÄ±nÄ± topla
tool_versions = {}
for name, cmd in tools.items():
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    output = (result.stdout + result.stderr).strip().split('\n')[0]
    tool_versions[name] = output

# Dosyaya yaz
with open(log_path, 'w') as f:
    f.write("=" * 60 + "\n")
    f.write("COMPARATIVE ANALYSIS OF VARIANT CALLING PIPELINES\n")
    f.write("IN BREAST CANCER SOMATIC MUTATION DETECTION\n")
    f.write("=" * 60 + "\n")
    f.write(f"Ortam Kurulum Tarihi: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
    f.write(f"Platform: Google Colab (Free/Pro)\n\n")

    f.write("--- SÄ°STEM BÄ°LGÄ°LERÄ° ---\n")
    f.write(f"CPU Ã§ekirdek: {cpu_count}\n")
    f.write(f"RAM: {ram_gb:.1f} GB\n")
    f.write(f"GPU: {gpu_name}\n")
    f.write(f"OS: Ubuntu (Colab default)\n\n")

    f.write("--- KURULU ARAÃ‡LAR ---\n")
    for name, version in tool_versions.items():
        f.write(f"{name:12s}: {version}\n")

    f.write(f"\n--- CONDA BÄ°LGÄ°SÄ° ---\n")

# Conda bilgisini de ekle
!conda --version >> {log_path}
!conda list >> {log_path} 2>&1

print(f"Ortam bilgileri kaydedildi:")
print(f"    Drive: {log_path}")






#Data download process:
import os
import time
raw_dir = "/content/ngs_project/raw_data"
os.makedirs(raw_dir, exist_ok=True)

print(" TÃ¼mÃ¶r FASTQ dosyalarÄ± indiriliyor (SRR7890850)...")
print("   Kaynak: EBI/ENA (European Bioinformatics Institute)")
print("   Ã–rnek: HCC1395 - Triple-negative meme kanseri")
print("   Veri tipi: WES (Whole Exome Sequencing)")
print()

start = time.time()
# Read 1 (Forward read)
print("  R1 (forward read) indiriliyor...")
!wget -q --show-progress -O {raw_dir}/SRR7890850_1.fastq.gz \
    ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR789/000/SRR7890850/SRR7890850_1.fastq.gz

# Read 2 (Reverse read)
print("  R2 (reverse read) indiriliyor...")
!wget -q --show-progress -O {raw_dir}/SRR7890850_2.fastq.gz \
    ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR789/000/SRR7890850/SRR7890850_2.fastq.gz

elapsed = time.time() - start
print(f"\n  Ä°ndirme sÃ¼resi: {elapsed/60:.1f} dakika")

# Dosya boyutlarÄ±nÄ± kontrol et
for f in ["SRR7890850_1.fastq.gz", "SRR7890850_2.fastq.gz"]:
    path = f"{raw_dir}/{f}"
    if os.path.exists(path):
        size_gb = os.path.getsize(path) / (1024**3)
        print(f" {f}: {size_gb:.2f} GB")
    else:
        print(f" {f}: Ä°NDÄ°RÄ°LEMEDÄ°!")



print("ðŸ“¥ Normal FASTQ dosyalarÄ± indiriliyor (SRR7890851)...")
print("   Ã–rnek: HCC1395BL - SaÄŸlÄ±klÄ± B-lenfoblast (matched normal)")
print()

start = time.time()

# Read 1
print(" R1 (forward read) indiriliyor...")
!wget -q --show-progress -O {raw_dir}/SRR7890851_1.fastq.gz \
    ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR789/001/SRR7890851/SRR7890851_1.fastq.gz

# Read 2
print(" R2 (reverse read) indiriliyor...")
!wget -q --show-progress -O {raw_dir}/SRR7890851_2.fastq.gz \
    ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR789/001/SRR7890851/SRR7890851_2.fastq.gz

elapsed = time.time() - start
print(f"\n  Ä°ndirme sÃ¼resi: {elapsed/60:.1f} dakika")

# Dosya boyutlarÄ±nÄ± kontrol et
for f in ["SRR7890851_1.fastq.gz", "SRR7890851_2.fastq.gz"]:
    path = f"{raw_dir}/{f}"
    if os.path.exists(path):
        size_gb = os.path.getsize(path) / (1024**3)
        print(f" {f}: {size_gb:.2f} GB")
    else:
        print(f" {f}: Ä°NDÄ°RÄ°LEMEDÄ°!")

# Toplam ham veri Ã¶zeti
print("\n" + "="*50)
print(" HAM VERÄ° Ã–ZETÄ°:")
print("="*50)
total = 0
for f in os.listdir(raw_dir):
    if f.endswith('.fastq.gz'):
        size = os.path.getsize(f"{raw_dir}/{f}") / (1024**3)
        total += size
        label = "TÃœMÃ–R" if "850" in f else "NORMAL"
        read = "R1" if "_1" in f else "R2"
        print(f"   {label:6s} {read}: {f} ({size:.2f} GB)")
print(f"\n   TOPLAM: {total:.2f} GB")



import time
import os

ref_dir = "/content/ngs_project/reference"

print(" Referans genom indiriliyor (GRCh38)...")
print("   Kaynak: NCBI FTP")
print("   ~3 GB dosya, 5-15 dakika suerebilir...\n")

start = time.time()

# NCBI'dan GRCh38 referans genomu indir
!wget -q --show-progress -O {ref_dir}/GRCh38.fa.gz \
    https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz

# Sikistirmayi ac
print("\nðŸ“¦ Dosya aciliyor (gunzip)...")
!gunzip -f {ref_dir}/GRCh38.fa.gz
!mv {ref_dir}/GRCh38.fa {ref_dir}/Homo_sapiens_assembly38.fasta 2>/dev/null || true

elapsed = time.time() - start

# Hangisi varsa onu bul
fasta_path = None
for name in ["Homo_sapiens_assembly38.fasta", "GRCh38.fa"]:
    p = f"{ref_dir}/{name}"
    if os.path.exists(p):
        fasta_path = p
        break

if fasta_path and os.path.getsize(fasta_path) / (1024**3) > 2.5:
    size_gb = os.path.getsize(fasta_path) / (1024**3)
    print(f"\n Referans genom: {size_gb:.2f} GB")
    print(f"   Dosya: {fasta_path}")
    print(f"  Toplam sure: {elapsed/60:.1f} dakika")
    print("\n FASTA formati ornegi (ilk 5 satir):")
    !head -5 {fasta_path}
else:
    print(" Indirme basarisiz!")
    print("   Dosyalar:")
    !ls -lh {ref_dir}/



import time
gt_dir = "/content/ngs_project/ground_truth"
ref_dir = "/content/ngs_project/reference"

print(" Ground Truth ve Known Sites dosyalari indiriliyor...\n")

# --- 1) GROUND TRUTH (cevap anahtari) ---
print("1ï¸  Ground Truth VCF (SEQC2 high-confidence somatic SNVs)...")
start = time.time()
!wget -q --show-progress -O {gt_dir}/high-confidence_sSNV_in_HC_regions_v1.2.vcf.gz \
    https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/seqc/Somatic_Mutation_WG/release/latest/high-confidence_sSNV_in_HC_regions_v1.2.vcf.gz

# Index dosyasi da lazim (tabix index - VCF'i hizli aramak icin)
!wget -q --show-progress -O {gt_dir}/high-confidence_sSNV_in_HC_regions_v1.2.vcf.gz.tbi \
    https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/seqc/Somatic_Mutation_WG/release/latest/high-confidence_sSNV_in_HC_regions_v1.2.vcf.gz.tbi

# High-confidence regions BED dosyasi (sadece bu bolgeler degerlendirilecek)
!wget -q --show-progress -O {gt_dir}/high-confidence_regions_v1.2.bed.gz \
    https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/seqc/Somatic_Mutation_WG/release/latest/high-confidence_regions_v1.2.bed.gz

elapsed1 = time.time() - start
print(f"   {elapsed1:.0f} saniye\n")

# --- 2) dbSNP (bilinen germline varyantlar) ---
print("2ï¸  dbSNP (known germline variants - BQSR icin)...")
start = time.time()
!wget -q --show-progress -O {ref_dir}/dbsnp_146.hg38.vcf.gz \
    https://storage.googleapis.com/gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf.gz 2>/dev/null \
    || wget -q --show-progress -O {ref_dir}/dbsnp_146.hg38.vcf.gz \
    https://ftp.ncbi.nlm.nih.gov/snp/organisms/human_9606/VCF/00-common_all.vcf.gz

!wget -q --show-progress -O {ref_dir}/dbsnp_146.hg38.vcf.gz.tbi \
    https://storage.googleapis.com/gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf.gz.tbi 2>/dev/null || true

elapsed2 = time.time() - start
print(f"    {elapsed2:.0f} saniye\n")

# --- 3) Known Indels (Mills & 1000G) ---
print("3ï¸  Known Indels (Mills & 1000 Genomes - BQSR icin)...")
start = time.time()
!wget -q --show-progress -O {ref_dir}/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \
    https://storage.googleapis.com/gcp-public-data--broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz 2>/dev/null || true

!wget -q --show-progress -O {ref_dir}/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz.tbi \
    https://storage.googleapis.com/gcp-public-data--broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz.tbi 2>/dev/null || true

elapsed3 = time.time() - start
print(f"     {elapsed3:.0f} saniye\n")

# --- OZET ---
print("=" * 55)
print(" INDIRILEN DOSYALAR OZETI:")
print("=" * 55)

all_files = []
for directory, label in [(gt_dir, "GROUND TRUTH"), (ref_dir, "REFERANS")]:
    for f in sorted(os.listdir(directory)):
        path = f"{directory}/{f}"
        size = os.path.getsize(path)
        if size > 0:
            if size > 1024**3:
                size_str = f"{size/(1024**3):.2f} GB"
            elif size > 1024**2:
                size_str = f"{size/(1024**2):.1f} MB"
            else:
                size_str = f"{size/1024:.1f} KB"
            print(f"    [{label:12s}] {f}: {size_str}")
            all_files.append(f)
        else:
            print(f"    [{label:12s}] {f}: BOS DOSYA!")

# Ground truth VCF'deki varyant sayisini goster
print(f"\n Ground Truth VCF istatistikleri:")
!zgrep -v "^#" {gt_dir}/high-confidence_sSNV_in_HC_regions_v1.2.vcf.gz 2>/dev/null | wc -l | xargs -I{} echo "   Toplam SNV sayisi: {}"





import datetime
import os

drive_base = "/content/drive/MyDrive/NGS_Project"
log_path = f"{drive_base}/logs/data_download_summary.txt"
os.makedirs(f"{drive_base}/logs", exist_ok=True)

raw_dir = "/content/ngs_project/raw_data"
ref_dir = "/content/ngs_project/reference"
gt_dir = "/content/ngs_project/ground_truth"

with open(log_path, 'w') as f:
    f.write("=" * 60 + "\n")
    f.write("VERI INDIRME OZETI\n")
    f.write(f"Tarih: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
    f.write("Runtime: H100 GPU\n")
    f.write("=" * 60 + "\n\n")
    f.write("--- FASTQ ---\n")
    for fname in sorted(os.listdir(raw_dir)):
        size = os.path.getsize(f"{raw_dir}/{fname}") / (1024**3)
        label = "TUMOR" if "850" in fname else "NORMAL"
        f.write(f"  {fname}: {size:.2f} GB [{label}]\n")
    f.write("\n--- REFERANS + KNOWN SITES ---\n")
    for fname in sorted(os.listdir(ref_dir)):
        size = os.path.getsize(f"{ref_dir}/{fname}")
        if size > 1024**3:
            f.write(f"  {fname}: {size/(1024**3):.2f} GB\n")
        elif size > 1024**2:
            f.write(f"  {fname}: {size/(1024**2):.1f} MB\n")
        else:
            f.write(f"  {fname}: {size/1024:.1f} KB\n")
    f.write("\n--- GROUND TRUTH ---\n")
    f.write("SNV sayisi: 39,648\n")
    for fname in sorted(os.listdir(gt_dir)):
        size = os.path.getsize(f"{gt_dir}/{fname}")
        if size > 1024**2:
            f.write(f"  {fname}: {size/(1024**2):.1f} MB\n")
        elif size > 0:
            f.write(f"  {fname}: {size/1024:.1f} KB\n")

print(f" Kaydedildi: {log_path}")
print("ADIM 2 TAMAMLANDI! Siradaki: QC (FastQC + fastp)")








import os
import time
raw_dir = "/content/ngs_project/raw_data"
qc_raw_dir = "/content/ngs_project/qc_raw"
os.makedirs(qc_raw_dir, exist_ok=True)

print(" FastQC calistiriliyor (ham veri uzerinde)...")
print("   4 dosya analiz edilecek, ~10-20 dk surabilir.\n")

start = time.time()

!fastqc \
    {raw_dir}/SRR7890850_1.fastq.gz \
    {raw_dir}/SRR7890850_2.fastq.gz \
    {raw_dir}/SRR7890851_1.fastq.gz \
    {raw_dir}/SRR7890851_2.fastq.gz \
    -o {qc_raw_dir} \
    -t 2 \
    --quiet

elapsed = time.time() - start
print(f"\n  FastQC suresi: {elapsed/60:.1f} dakika")

# Olusturulan dosyalari listele
print("\n Olusturulan QC raporlari:")
for f in sorted(os.listdir(qc_raw_dir)):
    size = os.path.getsize(f"{qc_raw_dir}/{f}") / 1024
    ftype = "HTML rapor" if f.endswith(".html") else "ZIP arsiv"
    print(f"    {f} ({size:.0f} KB) [{ftype}]")

# Drive'a kopyala
drive_qc = "/content/drive/MyDrive/NGS_Project/results/qc"
os.makedirs(drive_qc, exist_ok=True)
!cp {qc_raw_dir}/*.html {drive_qc}/
print(f"\n HTML raporlar Drive'a kaydedildi: {drive_qc}/")
print("   GitHub: results/qc/ klasorune eklenecek")

# Temel istatistikleri goster
print("\n FASTQ Temel Istatistikleri:")
print("-" * 65)
for gz in sorted(os.listdir(raw_dir)):
    if gz.endswith('.fastq.gz'):
        label = "TUMOR" if "850" in gz else "NORMAL"
        read = "R1" if "_1" in gz else "R2"
        # Read sayisini hizlica hesapla (ilk 4000 satir = 1000 read)
        count = !zcat {raw_dir}/{gz} 2>/dev/null | wc -l
        total_reads = int(count[0]) // 4
        print(f"   {label:6s} {read}: {gz}")
        print(f"          Toplam read sayisi: {total_reads:,}")
        print()




import os
import time

raw_dir = "/content/ngs_project/raw_data"
clean_dir = "/content/ngs_project/clean_data"
os.makedirs(clean_dir, exist_ok=True)

drive_qc = "/content/drive/MyDrive/NGS_Project/results/qc"

print(" fastp ile tumor verisi temizleniyor...")
print("   Adaptor kesme + kalite filtreleme + kisa read filtreleme")
print("   ~5-10 dakika surabilir.\n")

start = time.time()

!fastp \
    --in1 {raw_dir}/SRR7890850_1.fastq.gz \
    --in2 {raw_dir}/SRR7890850_2.fastq.gz \
    --out1 {clean_dir}/SRR7890850_1.clean.fastq.gz \
    --out2 {clean_dir}/SRR7890850_2.clean.fastq.gz \
    --json {clean_dir}/tumor_fastp.json \
    --html {clean_dir}/tumor_fastp.html \
    --qualified_quality_phred 20 \
    --length_required 50 \
    --detect_adapter_for_pe \
    --thread 2

elapsed = time.time() - start
print(f"\n  fastp suresi: {elapsed/60:.1f} dakika")

# HTML raporu Drive'a kopyala
!cp {clean_dir}/tumor_fastp.html {drive_qc}/tumor_fastp.html

# JSON rapordan temel istatistikleri cek
import json
with open(f"{clean_dir}/tumor_fastp.json", 'r') as f:
    report = json.load(f)

before = report['summary']['before_filtering']
after = report['summary']['after_filtering']

print("\n TUMOR FASTP OZETI:")
print("-" * 50)
print(f"   TEMIZLIK ONCESI:")
print(f"     Toplam read:    {before['total_reads']:,}")
print(f"     Toplam baz:     {before['total_bases']:,}")
print(f"     Q20 orani:      {before['q20_rate']*100:.1f}%")
print(f"     Q30 orani:      {before['q30_rate']*100:.1f}%")
print(f"     GC icerik:      {before['gc_content']*100:.1f}%")

print(f"\n   TEMIZLIK SONRASI:")
print(f"     Toplam read:    {after['total_reads']:,}")
print(f"     Toplam baz:     {after['total_bases']:,}")
print(f"     Q20 orani:      {after['q20_rate']*100:.1f}%")
print(f"     Q30 orani:      {after['q30_rate']*100:.1f}%")
print(f"     GC icerik:      {after['gc_content']*100:.1f}%")

kept_pct = (after['total_reads'] / before['total_reads']) * 100
print(f"\n   SONUC: %{kept_pct:.1f} read korundu")
print(f"    HTML rapor: {drive_qc}/tumor_fastp.html")
print(f"      GitHub: results/qc/tumor_fastp.html")


